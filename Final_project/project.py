"""
NAME:
    ConvAI

DESCRIPTION:
    This project implements a Python-based AI chatbot that interacts with a user using the Ollama model. 
    The chatbot can engage in conversation, save the conversation history, 
    and offer system-level instructions.

FEATURES:
    - User input is processed interactively.
    - The chatbot's responses are generated by the Ollama model.
    - The conversation history is saved and loaded from a JSON file.
    - The chatbot's behavior can be customized with system-level instructions.
    - Emoji conversion occurs as the user types, enhancing the interactive experience.
    - The chatbot supports commands to clear the screen and exit the conversation.

REQUIREMENTS:
    - Python 3.x
    - ollama
    - prompt_toolkit
    - emoji

AUTHOR: Ranjit Pokharel

CLASS:
    ArtificialIntelligence: A class that provides conversational AI capabilities.

FUNCTIONS:
    take_user_input(prompt: str) -> str
    clear_screen(command_for_screen_clear: list) -> bool
    requirement_check(model: str) -> None:
"""

import subprocess as sp
from prompt_toolkit import PromptSession
from prompt_toolkit.key_binding import KeyBindings
import typing
import ollama
import json
import emoji
import sys
import os


class ArtificialIntelligence:
    """
    A class that provides conversational AI capabilities.

    Attributes:
        model (str): The name of the AI model to use.
        conversation_memory_file (str): Path to the file storing the conversation history.
        system_edit (dict): System-level configuration to customize AI behavior.
        conversation_datas (list): List of conversation exchanges.

    Methods:
        load_memory(): Loads conversation history from the specified file.
        save_memory(): Saves the conversation history to a file.
        chat(question: str): Sends a query to the AI model and processes the response.
        system_level(): Initializes or updates system-level instructions in the conversation.
    """

    def __init__(
        self, model: str, conversation_memory_file: str, system_edit: dict = {}
    ) -> None:
        """
        Initializes the AI instance.

        Args:
            model (str): The AI model name (e.g., "llama3.2").
            conversation_memory_file (str): Path to the conversation history file.
            system_edit (dict, optional): Custom configuration for the AI system. Defaults to {}.
        """
        self.system_edit: dict[str, str] = system_edit
        self.model: str = model
        self.conversation_memory_file: str = conversation_memory_file
        self.conversation_datas: list[dict[str, str]] = []
        self.load_memory()
        self.system_level()

    def load_memory(self) -> None:
        """
        Loads the conversation history from the specified file.

        - If the file does not exist, it creates the necessary directory and file.
        - If the file is empty or has invalid data, initializes an empty history.
        """
        if not os.path.exists(self.conversation_memory_file):
            os.makedirs(os.path.dirname(self.conversation_memory_file), exist_ok=True)
            with open(self.conversation_memory_file, "w") as json_file:
                json.dump([], json_file)

        with open(self.conversation_memory_file, "r") as file:
            try:
                self.conversation_datas = json.load(file)
            except json.JSONDecodeError:
                self.conversation_datas = []

    def save_memory(self) -> None:
        """
        Saves the conversation history to the specified file.

        Raises:
            Exception: If an error occurs during the saving process.
        """
        try:
            with open(self.conversation_memory_file, "w") as file:
                json.dump(self.conversation_datas, file, indent=4)
        except Exception as e:
            raise e

    def chat(self, question: str) -> None:
        """
        Sends a query to the AI model and processes the response.

        Args:
            question (str): The user's query or statement.

        - Appends the user's message to the conversation history.
        - Streams the AI's response and appends it to the history.
        - Saves the updated conversation history.
        """
        user: dict[str, str] = {"role": "user", "content": question}
        self.conversation_datas.append(user)

        response: ollama.ChatResponse = ollama.chat(
            model=self.model, messages=self.conversation_datas, stream=True
        )
        full_chat: str = ""
        role: str = ""
        for chunk in response:
            role = chunk["message"]["role"]
            msg: tuple[str, typing.Any] = chunk["message"]["content"]
            print(msg, end="", flush=True)
            full_chat += msg

        self.conversation_datas.append({"role": role, "content": full_chat})
        self.save_memory()

    def system_level(
        self,
    ) -> None:
        """
        Initializes or updates system-level instructions in the conversation.

        - Ensures valid `system_edit` configuration exists.
        - Adds or updates the system message in the conversation history.
        """
        if len(self.system_edit) == 0:
            return

        is_not_system = self.system_edit.get("role") != "system"
        no_content = "content" not in self.system_edit
        no_text_in_content = not isinstance(self.system_edit["content"], str)

        if is_not_system and no_content and no_text_in_content:
            return

        if len(self.conversation_datas) == 0:
            self.conversation_datas.append(self.system_edit)
            return

        for data in self.conversation_datas:
            if data.get("role") == "system":
                data["content"] = self.system_edit["content"]
                return


def main() -> None:
    """
    starts the program and handles the conversation loop.

    Actions:
    - Checks the system for required apps and models.
    - Loads or initializes user data (name and AI name).
    - Loads conversation history or initializes a new history.
    - Starts a conversation loop where the user can interact with the AI.
    - Handles commands like quit, clear screen, etc.
    - Saves the conversation history before exiting.

    Raises:
        SystemExit: If required apps or models are missing or if saving history fails.
        KeyboardInterrupt: to exit.
    """
    user_file_path: str = "user/user_data.json"
    model: str = "llama3.2:1b"
    conversation_path: str = "conversation/data.json"

    user_datas: list[dict[str, str]] = user_setup(user_file_path)

    for usr_data in user_datas:
        usr_name: str = usr_data.get("user")
        ai_name: str = usr_data.get("ainame")
        ai_disc: str = usr_data.get("desc")

    command: str = ""
    greet = f"{ai_name.title().strip()}: "
    user = f"{usr_name.title().strip()}: "

    set_system = {
        "role": "system",
        "content": f"assistant name '{ai_name}', assistant discription '{ai_disc}'. user name '{usr_name}'.",
    }

    ai = ArtificialIntelligence(
        model=model,
        conversation_memory_file=conversation_path,
        system_edit=set_system,
    )

    try:
        while True:
            print()
            command = take_user_input(user)
            print()

            if command in ["@exit"]:
                raise KeyboardInterrupt

            elif command == "@clear":
                clear_screen(["clear"])

            else:
                print(greet, end="")
                ai.chat(command)
                print()

    except KeyboardInterrupt:
        command = "goodbye"
        print()
        print(greet, end="")
        ai.chat(command)
        print()


def take_user_input(prompt: str) -> str:
    """
    Prompts the user for input and returns the input after processing.

    Args:
        prompt (str): The prompt string to display to the user.

    Returns:
        str: The processed user input.
    """
    user_input: str = ""
    session = PromptSession()
    bindings = KeyBindings()
    
    # realtime emoji conversion as user type
    @bindings.add("<any>")
    def update_input_buffer(event):
        # binding add <any> will capture all the key pressed
        # insert_text is needed to insert the text as we type.
        event.app.current_buffer.insert_text(event.data)

        # converts to emoji as user type
        current_text = session.app.current_buffer.text
        updated_text = emoji.emojize(current_text, language="alias")
        session.app.current_buffer.text = updated_text

    user_input = session.prompt(
        prompt,
        key_bindings=bindings,
    )
    return str(user_input).strip()


def clear_screen(command_for_screen_clear: list) -> bool:
    """
    Attempts to clear the terminal screen using the specified command.

    Args:
        command_for_screen_clear (list): A list containing the command to clear the screen (e.g., ['clear']).

    Returns:
        bool: True if the screen was successfully cleared, False otherwise.

    Exceptions:
        subprocess.CalledProcessError: If the command fails to execute.
    """
    try:
        result: sp.CalledProcessError[bytes] = sp.run(command_for_screen_clear)
        if result.returncode == 0:
            return True
    except Exception as e:
        print(e)
        return False
    return False


def requirement_check(model: str) -> None:
    """
    Checks if the required apps and the specified AI model are installed and accessible.

    Args:
        modle (str): The AI model to check.

    Raises:
        SystemExit: If any required app or model is missing.
    """

    apps = [
        "python3",
        "ollama",
    ]

    for app in apps:
        result = sp.run(["which", app], capture_output=True)
        if result.returncode != 0:
            sys.exit(f"missing {app}. Install {app} and re-run.")

    result = sp.run(["ollama", "show", model], capture_output=True)
    if result.returncode != 0:
        sys.exit(f"missing {model}: run ollama pull {model}.")


def user_setup(
    user_file_path: str,
) -> list[dict[str, str]]:
    """
    Sets up or loads user data from a JSON file.

    If the file doesn't exist, prompts the user for their name, the AI's name, and a description,
    then saves this information. If the file exists, loads and returns the data.

    Args:
        user_file_path (str): Path to the user data JSON file.

    Returns:
        list[dict[str, str]]: User and AI configuration data, including name and description.
    """
    if not os.path.exists(user_file_path):
        os.makedirs(os.path.dirname(user_file_path), exist_ok=True)
        user_name: str = take_user_input("User Name: ")
        ai_name: str = take_user_input("AI Name: ")
        description: str = take_user_input("AI description: ")

        with open(user_file_path, "w") as json_file:
            json.dump(
                [{"user": user_name, "ainame": ai_name, "desc": description}],
                json_file,
                indent=4,
            )

    with open(user_file_path, "r") as file:
        try:
            return json.load(file)
        except json.JSONDecodeError:
            print("Error setting user data. going default mode.")
            print(f"setup can also be done by editing json file {user_file_path}")
            return [{"user": "user", "ainame": "ai", "desc": "None"}]


if __name__ == "__main__":
    main()
